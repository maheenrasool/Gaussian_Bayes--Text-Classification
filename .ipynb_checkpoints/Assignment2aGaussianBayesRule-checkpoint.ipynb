{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Assignment No 2a\n",
    "###### *Sibt ul Hussain*\n",
    "----\n",
    "## Goal\n",
    "\n",
    "Your goal in this assigment is to implement a Gaussian Bayes Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three different flavours of Bayes Rule\n",
    "\n",
    "- Binomial Bayes (We saw last time, in case of spam classification)\n",
    "- Multinomial Bayes\n",
    "- **Gaussian Bayes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "- Do not modify the block with test cases.\n",
    "- Do not tailor your solution to only pass the test cases. We will use different data for grading so keep your solution generic.\n",
    "- Passing all the cases means you are in reight direction, but does not ensure 100% marks, there may be some other cases hidden, so carefully read the question statement and implement all the necessory functionality.\n",
    "- <p style=\"color:#ff0000\">Plagiarism of any kind, (including internet) will lead to zero marks.</p>\n",
    "\n",
    "#### Libraries\n",
    "Ther are two additional libraries used which are not included in Anaconda package, nose and seaborn. You can install them using the following commands :\n",
    "```sh\n",
    "conda install -c anaconda nose=1.3.7\n",
    "conda install -c anaconda seaborn=0.7.1\n",
    "```\n",
    "Version of different libraries used are listed below:\n",
    "- Matplotlib **1.5.1**\n",
    "- Pandas **0.18.1**\n",
    "- Numpy **1.11.1**\n",
    "- Scipy **0.17.1**\n",
    "- Seaborn **0.7.1**\n",
    "\n",
    "Code for checking version info is present in cell below.\n",
    "\n",
    "#### Dead Kernal\n",
    "In case kernel does not connect, and shows a dead kernal meggese in read : \n",
    "- Go to Kernal -> Change kernal, and choose any of the available kernels.\n",
    "- Press ctrl + s and close the tab.\n",
    "- Open the notebook again and the kernel will connect. If it still does not connect then go to Kernel -> restart.\n",
    "\n",
    "**Note : ** Accuracies may slightly vary due to randomness in train-text split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "#many important functions are already written and provided in tools.py \n",
    "# please have a look at these functions....\n",
    "import tools as t\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Matplotlib version : \", matplotlib.__version__\n",
    "print \"Pandas version : \", pd.__version__\n",
    "print \"Numpy version : \", np.__version__\n",
    "print \"Scipy version : \", scipy.__version__\n",
    "print \"Seaborn version : \", sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2a6aef60ef58612e9eba39d429581b7a",
     "grade": false,
     "grade_id": "bayes_classifier",
     "locked": false,
     "solution": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "class GaussianBayes:\n",
    "    ''' Implements the Gaussian Bayes For Classification... '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self, X, Y):\n",
    "        ''' Train the multiclass (or Binary) Bayes Rule using the given \n",
    "            X [m x n] data matrix and Y labels matrix'''\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Run the trained classifiers on the given set of examples \n",
    "            For each example, you should return probability and its assigned class\n",
    "            Input: X of m x d\n",
    "            Output:\n",
    "            pclasses: predicted class of each example\n",
    "            probability: probability of each example falling in that predicted class...\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.test(X)[0]    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "print data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get your data in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "print \" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Lets plot the Complete data, with its covariance matrix...\n",
    "# Remember seeing is believing\n",
    "featnames=data.columns\n",
    "t.plotCov(X[:,2:],Y,labels=featnames.values[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Training and Testing Sets\n",
    "There must be a validation set but for this case we are using only two sets, training and validation sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print \" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   \n",
    "print \" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Lets plot the training data...\n",
    "t.plotCov(Xtrain[:,2:],Ytrain, labels=featnames.values[2:4])\n",
    "# so we will be estimating these covariance matrices and means..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Lets plot the test data...\n",
    "t.plotCov(Xtest[:,2:],Ytest,labels=featnames.values[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training Time\n",
    "========\n",
    "Let's train a Gaussian Bayes, first using two attributes.\n",
    "- What Two Attributes to use ? Any Guess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets train a Gaussian Bayes Classifier on Petal Length and Width\n",
    "gb=GaussianBayes()\n",
    "gb.train(Xtrain[:,2:],Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Lets test it on the set of unseen examples...\n",
    "\n",
    "pclasses,res=gb.test(Xtest[:,2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets see how good we are doing...\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Lets see how good we are doing...\n",
    "print pclasses==Ytest\n",
    "print Ytest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Using Just two attributes, accuracy is \n",
    "\n",
    "print np.sum(pclasses==Ytest)\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print \" Plotting the Decision Surface of Training Set... \"\n",
    "t.plot_decision_regions(Xtrain[:,2:],Ytrain,clf=gb, res=0.02, cycle_marker=True, legend=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases for your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ff1f6fb6d2cf29efaff377c4b2fe7734",
     "grade": true,
     "grade_id": "tests_bayes_classifier_two_features",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal, assert_is_not_none\n",
    "import pandas as pd\n",
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "\n",
    "data_val = pd.read_csv('./iris_val.data')\n",
    "data_val.columns = ['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "X_val = np.asarray(data_val[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y_val = np.asarray(data_val['Class'].dropna())\n",
    "\n",
    "gb_val=GaussianBayes()\n",
    "gb_val.train(X[:,2:],Y)\n",
    "pclasses_val, _ = gb_val.test(X_val[:,2:])\n",
    "acc_val = np.sum(pclasses_val == Y_val) / float(pclasses_val.shape[0])\n",
    "\n",
    "assert_greater_equal(acc_val, 0.90, msg=\"Acc must be greater then 90%\")\n",
    "\n",
    "cls =gb_val.predict(np.array([2,2]).reshape((1,2)))\n",
    "assert_is_not_none(cls, msg=\"Predict should work for single example\")\n",
    "\n",
    "print \"All cases passed !\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What can you conclude from the above decision Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation\n",
    "\n",
    "Since our dataset is not too big, to ensure that we are reporting true picture of our classifier, \n",
    "we will have to cross validate and report the mean accuracy across the folds to reflect the true \n",
    "picture of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets cross validate, and test the result...\n",
    "nfolds=4\n",
    "folds=t.generate_folds(X,Y,nfolds)\n",
    "\n",
    "#now lets train and test on these folds...\n",
    "totacc=[]\n",
    "for k in range(nfolds):\n",
    "    gb=GaussianBayes()\n",
    "    gb.train(folds[k][0][:,2:],folds[k][1])\n",
    "    pclasses,res=gb.test(folds[k][2][:,2:])\n",
    "    acc=np.sum(pclasses==folds[k][3])/float(folds[k][3].shape[0])\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)\n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc, 'Mean Accuracy =', np.mean(totacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Hmm Quite Impressive...\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets go and use all the four attributes...\n",
    "gb.train(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pclasses,res=gb.test(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Do you expect your Test accuracy to increase or decrease ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Using all four attributes, accuracy is \n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases for all four attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a74a24ac620b296f338f82bf3aa55c9b",
     "grade": true,
     "grade_id": "tests_bayes_classifier_all_features",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal, assert_is_not_none\n",
    "import pandas as pd\n",
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "\n",
    "data_val = pd.read_csv('./iris_val.data')\n",
    "data_val.columns = ['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "X_val = np.asarray(data_val[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y_val = np.asarray(data_val['Class'].dropna())\n",
    "\n",
    "gb_val=GaussianBayes()\n",
    "gb_val.train(X,Y)\n",
    "pclasses_val, _ = gb_val.test(X_val)\n",
    "acc_val = np.sum(pclasses_val == Y_val) / float(pclasses_val.shape[0])\n",
    "\n",
    "assert_greater_equal(acc_val, 0.90, msg=\"Acc must be greater then 90%\")\n",
    "\n",
    "cls =gb_val.predict(np.array([2,2,2,2]).reshape((1,4)))\n",
    "assert_is_not_none(cls, msg=\"Predict should work for single example\")\n",
    "\n",
    "print \"All cases passed !\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What can you conclude ?\n",
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's change the features... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "features=[0, 1]\n",
    "gb.train(Xtrain[:,features],Ytrain)\n",
    "pclasses,res=gb.test(Xtest[:,features])\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember Features are the important !!\n",
    "======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "t.plot_decision_regions(Xtest[:,features],Ytest,clf=gb, res=0.02, cycle_marker=True, legend=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Find the best pair of features (that gives maximum mean cross-validation accuracy) from all the available pairs for the problem in hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
